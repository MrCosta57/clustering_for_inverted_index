{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval and Web Search\n",
    "<p>\n",
    "Course Project - Clustering documents to compress inverted index<br>\n",
    "Giovanni Costa - 880892\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from scipy.sparse import save_npz, load_npz, vstack\n",
    "from sklearn.cluster import DBSCAN, MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from utils import parse_data_files, get_tfidf_repr, TSP_solver, stream_cluster, sort_csr_by_nonzero\n",
    "\n",
    "input_path=\"input/\"\n",
    "output_path=\"output/\"\n",
    "CORE_NUM=multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data parsing and TF-IDF representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=parse_data_files()\n",
    "print(\"Dataframe info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_docs, tf_idf_vocab=get_tfidf_repr(df)\n",
    "print(\"TF-IDF info:\")\n",
    "print(\"Shape: \", sparse_docs.shape)\n",
    "print(\"Size in MB: {:.3f} \".format(sparse_docs.data.nbytes/ (1024**2)))\n",
    "save_npz(input_path+\"sparse_tf-idf.npz\", sparse_docs)\n",
    "with open(input_path+\"tf-idf_vocab.pkl\", \"wb\") as file:\n",
    "    pickle.dump(tf_idf_vocab, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering and hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_docs_1=load_npz(input_path+'sparse_tf-idf.npz')\n",
    "tf_idf_vocab=None\n",
    "with open(input_path+'tf-idf_vocab.pkl', 'rb') as file:\n",
    "    tf_idf_vocab=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=sparse_docs_1[:10,:]\n",
    "sparse_docs=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" C=stream_cluster(sorted_collection,  0.1)\n",
    "elems=np.array([])\n",
    "labels=[]\n",
    "for label, cluster in enumerate(C):\n",
    "    tmp_len=len(cluster)\n",
    "    elems=np.concatenate([elems,cluster], axis=0)\n",
    "    labels+=[label]*tmp_len\n",
    "elems=vstack([e for e in elems]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\mambaforge\\envs\\ML-base\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.9914131 , 1.        , 1.        , 1.        ,\n",
       "        0.        , 1.        , 1.        , 0.        , 0.        ],\n",
       "       [0.5441225 , 0.7531114 , 0.55582774, 0.40665048, 0.5812186 ,\n",
       "        0.9983736 , 0.65728694, 0.5209922 , 0.9983736 , 0.9983736 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means=MiniBatchKMeans(n_clusters=2, batch_size=256*CORE_NUM).fit(sparse_docs)\n",
    "#get the total num of core of the cpu\n",
    "dist=cosine_distances(k_means.cluster_centers_, sparse_docs)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(dist, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Cluster Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=stream_cluster(sorted_collection,  radius)\n",
    "len(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_collection=sort_csr_by_nonzero(sparse_docs)\n",
    "results=[] #TODO: for debug purposes\n",
    "best_C=None\n",
    "best_radius=None\n",
    "max_res=-2 #silhouette_score is between [-1, 1]\n",
    "step=0.1\n",
    "for radius in np.arange(0.1, 1, step):\n",
    "    C=stream_cluster(sorted_collection,  radius)\n",
    "    elems=np.array([])\n",
    "    labels=[]\n",
    "    for label, cluster in enumerate(C):\n",
    "        tmp_len=len(cluster)\n",
    "        elems=np.concatenate([elems,cluster], axis=0)\n",
    "        labels+=[label]*tmp_len\n",
    "    elems=vstack([e for e in elems])\n",
    "    res=silhouette_score(elems, labels, metric='cosine')\n",
    "    if res>max_res:\n",
    "        best_C=C\n",
    "        max_res=res\n",
    "        best_radius=radius\n",
    "    results.append(res)\n",
    "#max_index=np.argmax(results)\n",
    "#final_radius=max_index*step\n",
    "print(\"Max silhouette score: \", max_res)\n",
    "print(\"Best radius parameter: \", best_radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter=5\n",
    "params_dbscan={\"min_samples\": [i for i in range(2, 35)],\n",
    "        \"eps\": [i for i in np.arange(0.1, 5.1, 0.1)]}\n",
    "dbscan=DBSCAN(metric=\"cosine\")\n",
    "searcher_dbscan=RandomizedSearchCV(dbscan, scoring=silhouette_score, n_iter=5, param_distributions=params_dbscan, cv=2, n_jobs=-1)\n",
    "searcher_dbscan.fit(sparse_docs)\n",
    "print(\"Best params: \", searcher_dbscan.best_params_)\n",
    "print(\"Best silhouette_score: \", searcher_dbscan.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_indices=searcher_dbscan.best_estimator_.core_sample_indices_\n",
    "core_points=sparse_docs[core_indices]\n",
    "core_points_distances=cosine_distances(core_points)\n",
    "dbscan_tsp=TSP_solver(core_points_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the labels given to the core samples (representative elements) in order to get the best cluster transversal ordering\n",
    "dbscan_cluster_order=core_points.labels_[core_indices[dbscan_tsp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for num in k_medoids_cluster_order:\n",
    "np.nonzero(k_medoids.labels_==8) #-1 is the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"terms\"].str.split(\" \").apply(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" print(\"DBSCAN Clustering\")\n",
    "params_dbscan={\"min_samples\": [i for i in range(2, 35)],\n",
    "        \"eps\": [i for i in np.arange(0.1, 5, 0.1)]}\n",
    "dbscan=DBSCAN(metric=\"cosine\")\n",
    "searcher_dbscan=RandomizedSearchCV(dbscan, scoring=silhouette_score, n_iter=n_iter, param_distributions=params_dbscan, cv=3, n_jobs=-1)\n",
    "searcher_dbscan.fit(sparse_doc)\n",
    "print(\"Best params: \", searcher_dbscan.best_params_)\n",
    "print(\"Best silhouette_score: \", searcher_dbscan.best_score_) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" medoid_indices=searcher_kmedoids.best_estimator_.medoid_indices_\n",
    "medoids=sparse_doc[medoid_indices]\n",
    "medoid_distances=cosine_distances(medoids) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" k_medoids_tsp=TSP_solver(medoid_distances) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" DBSCAN_indices=searcher_dbscan.best_estimator_.core_sample_indices_\n",
    "core_points=sparse_doc[DBSCAN_indices]\n",
    "core_points_distances=cosine_distances(core_points) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" dbscan_tsp=TSP_solver(core_points_distances) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
